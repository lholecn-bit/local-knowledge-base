# backend/app.py

import os
from dotenv import load_dotenv

# ğŸ”´ æœ€é‡è¦ï¼šåœ¨æœ€å¼€å§‹åŠ è½½ .env æ–‡ä»¶
load_dotenv()

from flask import Flask, request, jsonify, Response
from flask_cors import CORS
from knowledge_base import LocalKnowledgeBase
from pathlib import Path
import traceback
import json

# åˆå§‹åŒ– Flask åº”ç”¨
app = Flask(__name__)

# âœ… æ”¹è¿›çš„ CORS é…ç½® - æ”¯æŒæµå¼å“åº”
CORS(app, 
     resources={r"/api/*": {
         "origins": "*",
         "methods": ["GET", "POST", "DELETE", "OPTIONS"],
         "allow_headers": ["Content-Type", "Authorization"],
         "supports_credentials": True,
         "max_age": 3600
     }},
     expose_headers=["Content-Type", "X-Total-Count"],
     stream=True)  # âœ… å…³é”®ï¼æ”¯æŒæµå¼å“åº”

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'your-secret-key-change-in-production')

# åˆå§‹åŒ–çŸ¥è¯†åº“
print("\n" + "="*60)
print("ğŸš€ åˆå§‹åŒ–æœ¬åœ°çŸ¥è¯†åº“ç³»ç»Ÿ")
print("="*60)

try:
    kb = LocalKnowledgeBase()
    print("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸï¼\n")
except Exception as e:
    print(f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    print(f"   è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­æ˜¯å¦æœ‰ OPENAI_API_KEY")
    traceback.print_exc()
    kb = None


# ==================== API ç«¯ç‚¹ ====================

@app.route('/api/kb/stats', methods=['GET'])
def get_kb_stats():
    """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        stats = kb.get_stats()
        return jsonify(stats), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/documents/upload', methods=['POST'])
def upload_documents():
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        if 'files' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}), 400
        
        files = request.files.getlist('files')
        if not files:
            return jsonify({'error': 'æ–‡ä»¶åˆ—è¡¨ä¸ºç©º'}), 400
        
        print(f"\nğŸ“¤ ä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶...")
        result = kb.add_documents_from_upload(files)
        
        return jsonify(result), 200
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kb/search', methods=['POST'])
def search_kb():
    """æœç´¢çŸ¥è¯†åº“"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        query = data.get('query', '')
        top_k = data.get('top_k', 3)
        
        if not query:
            return jsonify({'error': 'æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        result = kb.search(query, top_k)
        return jsonify(result), 200
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/kb/query', methods=['POST'])
def query_kb():
    """æŸ¥è¯¢çŸ¥è¯†åº“"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        question = data.get('question', '')
        top_k = data.get('top_k', 3)
        
        if not question:
            return jsonify({'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'}), 400
        
        result = kb.query(question, top_k)
        return jsonify(result), 200
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/stream-query', methods=['POST', 'OPTIONS'])
def stream_query():
    """âœ… æµå¼æŸ¥è¯¢ç«¯ç‚¹"""
    if request.method == 'OPTIONS':
        return '', 204
    
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        data = request.get_json()
        question = data.get('question', '')
        mode = data.get('mode', 'auto')
        top_k = data.get('top_k', 3)
        use_stream = data.get('use_stream', True)
        
        if not question:
            return jsonify({'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'}), 400
        
        print(f"\nğŸ” æµå¼æŸ¥è¯¢: {question}")
        print(f"   æ¨¡å¼: {mode}, topK: {top_k}")
        
        # âœ… ä½¿ç”¨ç”Ÿæˆå™¨ç”Ÿæˆæµå¼æ•°æ®
        def generate():
            try:
                # è·å–ç›¸å…³æ–‡æ¡£
                search_results = kb.search(question, top_k)
                sources = [doc['source'] for doc in search_results['results']]
                
                # å‘é€å¼€å§‹ä¿¡å·
                yield json.dumps({
                    'type': 'start',
                    'mode': mode,
                    'sources': sources
                }) + '\n'
                
                if mode == 'kb':
                    # çŸ¥è¯†åº“æ¨¡å¼ï¼šç›´æ¥è¿”å›æœç´¢ç»“æœ
                    answer = "\n\n".join([
                        f"ã€{doc['source']}ã€‘\n{doc['content']}"
                        for doc in search_results['results']
                    ])
                    yield json.dumps({
                        'type': 'stream',
                        'data': answer or "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
                    }) + '\n'
                
                elif mode == 'llm':
                    # LLM æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨ LLM
                    from llm_client import LLMClient
                    
                    llm = LLMClient(
                        api_url=os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1'),
                        api_key=os.getenv('OPENAI_API_KEY'),
                        model=os.getenv('LLM_MODEL', 'gpt-3.5-turbo')
                    )
                    
                    # åŒæ­¥è°ƒç”¨ LLMï¼ˆç®€å•æ–¹å¼ï¼‰
                    answer = llm.chat(question)
                    yield json.dumps({
                        'type': 'stream',
                        'data': answer
                    }) + '\n'
                
                else:  # auto æ¨¡å¼
                    # å¦‚æœæœ‰ç›¸å…³æ–‡æ¡£ï¼Œå…ˆè¿”å›æ–‡æ¡£
                    if search_results['results']:
                        docs_answer = "\n\n".join([
                            f"ã€{doc['source']}ã€‘\n{doc['content']}"
                            for doc in search_results['results']
                        ])
                        yield json.dumps({
                            'type': 'stream',
                            'data': docs_answer
                        }) + '\n'
                    else:
                        # æ²¡æœ‰ç›¸å…³æ–‡æ¡£ï¼Œè°ƒç”¨ LLM
                        from llm_client import LLMClient
                        
                        llm = LLMClient(
                            api_url=os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1'),
                            api_key=os.getenv('OPENAI_API_KEY'),
                            model=os.getenv('LLM_MODEL', 'gpt-3.5-turbo')
                        )
                        answer = llm.chat(question)
                        yield json.dumps({
                            'type': 'stream',
                            'data': answer
                        }) + '\n'
                
                # å‘é€å®Œæˆä¿¡å·
                yield json.dumps({'type': 'done'}) + '\n'
            
            except Exception as e:
                print(f"âŒ æµå¼æŸ¥è¯¢é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                yield json.dumps({
                    'type': 'error',
                    'message': str(e)
                }) + '\n'
        
        # âœ… è¿”å›æµå¼å“åº”
        return Response(
            generate(),
            mimetype='application/x-ndjson',
            headers={
                'Content-Type': 'application/x-ndjson; charset=utf-8',
                'Cache-Control': 'no-cache',
                'Transfer-Encoding': 'chunked'
            }
        )
    
    except Exception as e:
        print(f"âŒ æµå¼æŸ¥è¯¢å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kb/clear', methods=['POST'])
def clear_kb():
    """æ¸…ç©ºçŸ¥è¯†åº“"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        kb.clear()
        return jsonify({'message': 'çŸ¥è¯†åº“å·²æ¸…ç©º'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/documents/list', methods=['GET'])
def list_documents():
    """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        stats = kb.get_stats()
        return jsonify({'files': stats.get('files', [])}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/documents/<filename>', methods=['DELETE'])
def delete_document(filename):
    """åˆ é™¤æ–‡æ¡£"""
    if not kb:
        return jsonify({'error': 'çŸ¥è¯†åº“æœªåˆå§‹åŒ–'}), 500
    
    try:
        kb.delete_document(filename)
        return jsonify({'message': f'æ–‡æ¡£å·²åˆ é™¤: {filename}'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'ok',
        'kb_initialized': kb is not None
    }), 200


# ==================== é”™è¯¯å¤„ç† ====================

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'ç«¯ç‚¹ä¸å­˜åœ¨'}), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'å†…éƒ¨æœåŠ¡å™¨é”™è¯¯'}), 500


if __name__ == '__main__':
    if kb:
        print("\n" + "="*60)
        print("ğŸŒ Flask åº”ç”¨å¯åŠ¨æˆåŠŸï¼")
        print("ğŸ“ è®¿é—®åœ°å€: http://localhost:3000")
        print("ğŸ“ å‰ç«¯åœ°å€: http://localhost:5000")
        print("="*60 + "\n")
        app.run(host='0.0.0.0', port=5000, debug=True)
    else:
        print("\nâŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨åº”ç”¨")
        print("   è¯·æ£€æŸ¥ .env æ–‡ä»¶å’Œä¾èµ–å®‰è£…\n")
