# RAG ç³»ç»Ÿç›¸å…³æ€§é˜ˆå€¼é—®é¢˜ - è¡Œä¸šè§£å†³æ–¹æ¡ˆ

## é—®é¢˜èƒŒæ™¯

å‘é‡ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆRelevance Thresholdï¼‰å¾ˆéš¾è°ƒæ•´çš„åŸå› ï¼š
1. **å‘é‡ç©ºé—´éçº¿æ€§** - ç›¸ä¼¼åº¦åˆ†æ•°ä¸å®é™…ç›¸å…³æ€§çš„æ˜ å°„å…³ç³»ä¸æ˜¯çº¿æ€§çš„
2. **åŸŸå·®å¼‚** - ä¸åŒé¢†åŸŸçš„å†…å®¹ç›¸ä¼¼åº¦åˆ†å¸ƒå®Œå…¨ä¸åŒ
3. **å‘é‡æ¨¡å‹é™åˆ¶** - text-embedding-3-small å¯¹æŸäº›ç»†å¾®å·®å¼‚ååº”ä¸æ•æ„Ÿ
4. **åŠ¨æ€æ€§** - çŸ¥è¯†åº“æ›´æ–°åé˜ˆå€¼æ•ˆæœä¼šå˜åŒ–

---

## è¡Œä¸šä¸»æµè§£å†³æ–¹æ¡ˆ

### ğŸ† æ–¹æ¡ˆ1ï¼šå¤šå±‚æ¬¡æ··åˆæ£€ç´¢ï¼ˆHybrid Retrievalï¼‰- â­ æ¨è

**æ ¸å¿ƒæ€æƒ³**ï¼šä¸ä¾èµ–å•ä¸€çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œè€Œæ˜¯ç»“åˆå¤šä¸ªä¿¡å·ã€‚

```python
# ä¼ªä»£ç 
results = []

# ç¬¬ä¸€å±‚ï¼šå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
vector_results = vector_search(query, top_k=10)

# ç¬¬äºŒå±‚ï¼šBM25 å…³é”®è¯æ£€ç´¢ï¼ˆç¨€ç–ï¼‰
keyword_results = bm25_search(query, top_k=10)

# ç¬¬ä¸‰å±‚ï¼šèåˆæ’åºï¼ˆRRF - Reciprocal Rank Fusionï¼‰
fused_results = rrf_fusion(vector_results, keyword_results)

# åªå–èåˆåçš„ top_k
return fused_results[:top_k]
```

**ä¼˜ç‚¹**ï¼š
- âœ… é¿å…å•ä¸€é˜ˆå€¼é—®é¢˜
- âœ… å…³é”®è¯åŒ¹é…è¡¥å……è¯­ä¹‰ç†è§£çš„ä¸è¶³
- âœ… é²æ£’æ€§å¼º

**ç¼ºç‚¹**ï¼š
- âŒ å®ç°å¤æ‚åº¦é«˜
- âŒ éœ€è¦é¢å¤–çš„æœç´¢å¼•æ“ï¼ˆå¦‚ Elasticsearchï¼‰

---

### ğŸ“Š æ–¹æ¡ˆ2ï¼šRe-Rankingï¼ˆé‡æ’åºï¼‰ - â­â­ æ¨è

**æ ¸å¿ƒæ€æƒ³**ï¼šå…ˆç”¨å‘é‡æ£€ç´¢å¿«é€Ÿå¬å›å¤§é‡å€™é€‰ï¼Œå†ç”¨ä¸“é—¨çš„é‡æ’åºæ¨¡å‹ç²¾ç»†åŒ–æ’åºã€‚

```python
# ä¼ªä»£ç 
# ç¬¬ä¸€æ­¥ï¼šå‘é‡æ£€ç´¢ï¼ˆå®½æ¾é˜ˆå€¼ï¼Œå¬å›å¤šä¸ªç»“æœï¼‰
candidates = vector_search(query, top_k=50, threshold=0.2)

# ç¬¬äºŒæ­¥ï¼šç”¨é‡æ’åºæ¨¡å‹é‡æ–°è¯„åˆ†
reranked = rerank_model.rank(query, candidates)

# ç¬¬ä¸‰æ­¥ï¼šå–å‰ top_k
return reranked[:top_k]
```

**ä½¿ç”¨çš„é‡æ’åºæ¨¡å‹**ï¼š
- **Cohere Rerank** - å•†ç”¨ï¼ˆæ•ˆæœæœ€å¥½ï¼‰
- **jina-reranker** - å¼€æºï¼ˆ3B å‚æ•°ï¼Œæ•ˆæœæ¬¡å¥½ï¼‰
- **bge-reranker** - å¼€æºï¼ˆè½»é‡çº§ï¼‰
- **LLM-based Ranking** - ç”¨ LLM é‡æ–°è¯„ä¼°ï¼ˆæ…¢ä½†å‡†ï¼‰

**æ¨èç”¨æ³•**ï¼š
```python
from sentence_transformers import CrossEncoder

reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# å¿«é€Ÿå¬å›
candidates = vector_store.similarity_search(query, k=50)

# é‡æ’åº
scores = reranker.predict([
    (query, doc.page_content) for doc in candidates
])

# æŒ‰åˆ†æ•°æ’åº
ranked_docs = sorted(
    zip(candidates, scores),
    key=lambda x: x[1],
    reverse=True
)[:top_k]
```

**ä¼˜ç‚¹**ï¼š
- âœ… ç²¾å‡†åº¦é«˜
- âœ… å¯ä»¥ç”¨å¼€æºæ¨¡å‹
- âœ… ç›¸å¯¹æ˜“å®ç°

**ç¼ºç‚¹**ï¼š
- âŒ å¤šä¸€å±‚æ¨ç†ï¼Œå»¶è¿Ÿå¢åŠ 
- âŒ éœ€è¦é¢å¤–è®¡ç®—èµ„æº

---

### ğŸ¤– æ–¹æ¡ˆ3ï¼šLLM å®¡æŸ¥ï¼ˆLLM-as-Judgeï¼‰ - â­â­â­ æœ€å¯é 

**æ ¸å¿ƒæ€æƒ³**ï¼šè®© LLM è‡ªå·±åˆ¤æ–­æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿç›¸å…³ï¼Œè€Œä¸æ˜¯ä¾èµ–ç¡¬é˜ˆå€¼ã€‚

```python
# ä¼ªä»£ç 
# ç¬¬ä¸€æ­¥ï¼šå®½æ¾æ£€ç´¢
candidates = vector_search(query, top_k=10, threshold=0.1)

# ç¬¬äºŒæ­¥ï¼šLLM è¯„ä¼°ç›¸å…³æ€§
relevant_docs = []
for doc in candidates:
    prompt = f"""
    é—®é¢˜ï¼š{query}
    æ–‡æ¡£å†…å®¹ï¼š{doc.content}
    
    è¯·åˆ¤æ–­è¿™ä¸ªæ–‡æ¡£æ˜¯å¦èƒ½å¸®åŠ©å›ç­”é—®é¢˜ã€‚
    å›ç­”ï¼šæ˜¯/å¦
    """
    decision = llm(prompt)
    if "æ˜¯" in decision:
        relevant_docs.append(doc)

# ç¬¬ä¸‰æ­¥ï¼šç”¨æœ€ç›¸å…³çš„æ–‡æ¡£å›ç­”
return relevant_docs
```

**ä¼˜ç‚¹**ï¼š
- âœ… æœ€ç¬¦åˆäººç±»åˆ¤æ–­
- âœ… å®Œå…¨é¿å…é˜ˆå€¼é—®é¢˜
- âœ… æ•ˆæœæœ€å¥½

**ç¼ºç‚¹**ï¼š
- âŒ é¢å¤–çš„ LLM è°ƒç”¨ï¼Œæˆæœ¬é«˜
- âŒ å»¶è¿Ÿæœ€é«˜

**æ”¹è¿›ç‰ˆæœ¬**ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰ï¼š
```python
# åªç”¨ LLM å®¡æŸ¥å‰ 3 ä¸ªå€™é€‰
candidates = vector_search(query, top_k=3)
for doc in candidates:
    if llm_judge(query, doc) == "ç›¸å…³":
        return doc
# å¦‚æœéƒ½ä¸ç›¸å…³ï¼Œç”¨å‘é‡ç»“æœçš„ç¬¬ä¸€ä¸ª
return candidates[0]
```

---

### ğŸ“ˆ æ–¹æ¡ˆ4ï¼šå­¦ä¹ å¼é˜ˆå€¼ï¼ˆLearning-basedï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šæ ¹æ®å†å²æ•°æ®è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜é˜ˆå€¼ã€‚

```python
# ä¼ªä»£ç 
# æ”¶é›†ç”¨æˆ·åé¦ˆæ•°æ®
training_data = [
    (query, doc, user_relevance_rating),  # 1-5 åˆ†
    ...
]

# è®­ç»ƒæ¨¡å‹æ‰¾åˆ°æœ€ä¼˜çš„å¾—åˆ† â†’ ç›¸å…³æ€§æ˜ å°„
optimal_threshold = learn_optimal_threshold(training_data)
```

**ä¼˜ç‚¹**ï¼š
- âœ… è‡ªé€‚åº”
- âœ… ç²¾å‡†åº¦é«˜

**ç¼ºç‚¹**ï¼š
- âŒ éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®
- âŒ å®ç°å¤æ‚

---

## ğŸ¯ é’ˆå¯¹ä½ çš„åœºæ™¯æ¨è

æ ¹æ®ä½ çš„é¡¹ç›®ç‰¹ç‚¹ï¼ˆæœ¬åœ°çŸ¥è¯†åº“ RAGï¼‰ï¼Œæˆ‘å»ºè®®çš„åˆ†é˜¶æ®µæ–¹æ¡ˆï¼š

### **ç¬¬ä¸€é˜¶æ®µï¼ˆç°åœ¨ï¼‰** âœ…
```
ä½¿ç”¨ï¼šRe-Ranking æ–¹æ¡ˆ
ç†ç”±ï¼š
- å¼€æºæ¨¡å‹ bge-reranker è½»é‡çº§ï¼Œå»¶è¿Ÿä½
- æ•ˆæœæ˜¾è‘—æå‡
- å®ç°ç›¸å¯¹ç®€å•
```

### **ç¬¬äºŒé˜¶æ®µï¼ˆå¦‚æœæ•ˆæœä¸ç†æƒ³ï¼‰**
```
ä½¿ç”¨ï¼šLLM-as-Judge çš„æˆæœ¬ä¼˜åŒ–ç‰ˆæœ¬
ç†ç”±ï¼š
- å……åˆ†åˆ©ç”¨å·²æœ‰çš„ LLM
- æˆæœ¬è¾ƒä½ï¼ˆåªå®¡æŸ¥å‰ 3 ä¸ªå€™é€‰ï¼‰
- æ•ˆæœæœ€ä½³
```

### **ç¬¬ä¸‰é˜¶æ®µï¼ˆè§„æ¨¡åŒ–ï¼‰**
```
ä½¿ç”¨ï¼šHybrid Retrieval
ç†ç”±ï¼š
- ç”Ÿäº§çº§ç³»ç»Ÿçš„æ ‡å‡†åšæ³•
- éœ€è¦é›†æˆ Elasticsearch
- æœ€å¯é 
```

---

## å¿«é€Ÿå¯¹æ¯”è¡¨

| æ–¹æ¡ˆ | æ•ˆæœ | å¤æ‚åº¦ | æˆæœ¬ | æ¨èæŒ‡æ•° |
|------|------|--------|------|---------|
| **å¤šé˜ˆå€¼è°ƒæ•´** | â­ | â­ | â­ | âŒ |
| **Re-Ranking** | â­â­â­â­ | â­â­ | â­â­ | âœ…âœ… |
| **LLM-as-Judge** | â­â­â­â­â­ | â­â­â­ | â­â­â­ | âœ…âœ…âœ… |
| **Hybrid Retrieval** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | âš ï¸ å¤æ‚ |
| **å­¦ä¹ å¼é˜ˆå€¼** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | âš ï¸ éœ€æ•°æ® |

---

## å¼€æºå·¥å…·æ¨è

### Re-Ranking åº“
```bash
pip install sentence-transformers
# æ¨¡å‹é€‰æ‹©ï¼š
# - cross-encoder/ms-marco-MiniLM-L-6-v2ï¼ˆå°ï¼Œå¿«ï¼‰
# - BAAI/bge-reranker-largeï¼ˆå¤§ï¼Œç²¾å‡†ï¼‰
```

### Hybrid Retrieval
```bash
pip install elasticsearch langchain-elasticsearch
```

### LLM Ranking
```bash
# ç›´æ¥ç”¨ç°æœ‰çš„ OpenAI API
# æ— éœ€é¢å¤–å®‰è£…
```

---

## å‚è€ƒèµ„æº

- [Langchain Re-ranking](https://python.langchain.com/docs/modules/data_connection/retrievers/long_context_reorder)
- [BGE Reranker GitHub](https://github.com/FlagOpen/FlagEmbedding)
- [Hybrid Search Best Practices](https://docs.pinecone.io/guides/hybrid-search)
- [RAG Evaluation Framework](https://github.com/langchain-ai/langsmith-cookbook)
