### çŸ¥è¯†åº“å›ç­”æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ ç”¨æˆ·
    participant Frontend as ğŸŒ å‰ç«¯<br/>(app.js)
    participant FrontendUI as ğŸ¨ UI<br/>(ui.js)
    participant AJAX as ğŸ“¡ HTTP<br/>(api.js)
    participant Backend as ğŸ”™ åç«¯<br/>(app.py)
    participant KB as ğŸ“š çŸ¥è¯†åº“<br/>(knowledge_base.py)
    participant LLM as ğŸ¤– LLM<br/>(llm_client.py)

    User->>Frontend: 1ï¸âƒ£ é€‰æ‹©ã€ŒğŸ“š çŸ¥è¯†åº“ã€æ¨¡å¼
    Frontend->>Frontend: conversationMode = 'kb'
    
    User->>FrontendUI: 2ï¸âƒ£ è¾“å…¥é—®é¢˜ + ç‚¹å‡»å‘é€
    FrontendUI->>Frontend: è§¦å‘ handleQuery()
    
    Frontend->>FrontendUI: 3ï¸âƒ£ æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    FrontendUI->>FrontendUI: addUserMessage(question)
    
    Frontend->>FrontendUI: 4ï¸âƒ£ åˆ›å»ºæµå¼æ¶ˆæ¯å®¹å™¨
    FrontendUI->>FrontendUI: addStreamMessage()<br/>currentMessageEl = <div>
    
    Frontend->>AJAX: 5ï¸âƒ£ å‘èµ·æµå¼è¯·æ±‚
    AJAX->>AJAX: POST /api/stream-query
    Note over AJAX: {<br/>  question: "é—®é¢˜",<br/>  mode: "kb",<br/>  top_k: 3,<br/>  use_stream: true<br/>}
    
    AJAX->>Backend: 6ï¸âƒ£ HTTP è¯·æ±‚åˆ°åç«¯
    
    Backend->>Backend: 7ï¸âƒ£ stream_query() æ¥æ”¶è¯·æ±‚
    Backend->>Backend: è§£æ data.get('mode') = 'kb'
    
    alt mode == 'kb' (çŸ¥è¯†åº“æ¨¡å¼)
        Backend->>KB: 8ï¸âƒ£ kb.search(question, top_k=3)
        KB->>KB: å‘é‡æœç´¢ + ç›¸ä¼¼åº¦åŒ¹é…
        KB-->>Backend: è¿”å›æœç´¢ç»“æœåˆ—è¡¨
        
        Backend->>Backend: 9ï¸âƒ£ æ ¼å¼åŒ–æœç´¢ç»“æœ
        Backend->>Backend: answer = "ã€æ–‡ä»¶1ã€‘\nå†…å®¹1\n\nã€æ–‡ä»¶2ã€‘\nå†…å®¹2"
        
        Backend->>AJAX: ğŸ”Ÿ yield start ä¿¡å·
        Note over Backend: {<br/>  "type": "start",<br/>  "mode": "kb",<br/>  "sources": [...]<br/>}
        
        Backend->>AJAX: 1ï¸âƒ£1ï¸âƒ£ yield stream æ•°æ®
        Note over Backend: {<br/>  "type": "stream",<br/>  "data": "ã€æ–‡ä»¶1ã€‘\n..."<br/>}
        
        Backend->>AJAX: 1ï¸âƒ£2ï¸âƒ£ yield done ä¿¡å·
        Note over Backend: {"type": "done"}
    else mode == 'auto' && æ— ç›¸å…³æ–‡æ¡£
        Backend->>LLM: è°ƒç”¨ llm.chat(question)
        LLM->>LLM: è°ƒç”¨ OpenAI API
        LLM-->>Backend: è¿”å› AI å›ç­”
        Backend->>AJAX: yield stream æ•°æ®
    end
    
    AJAX->>AJAX: 1ï¸âƒ£3ï¸âƒ£ æ¥æ”¶å“åº”æµ
    
    loop å¤„ç†æ¯ä¸€è¡Œ JSON æ•°æ®
        AJAX->>AJAX: è§£æ JSON è¡Œ
        
        alt type == 'start'
            AJAX->>FrontendUI: 1ï¸âƒ£4ï¸âƒ£ æ˜¾ç¤ºæ¥æºä¿¡æ¯
            FrontendUI->>FrontendUI: showSources(sources)
        else type == 'stream'
            AJAX->>FrontendUI: 1ï¸âƒ£5ï¸âƒ£ æ›´æ–°æµå¼å†…å®¹
            FrontendUI->>FrontendUI: updateStreamMessage(data)
            FrontendUI->>FrontendUI: contentDiv.textContent += data
            FrontendUI->>FrontendUI: å»¶è¿Ÿ 300ms åå¤„ç†
            FrontendUI->>FrontendUI: _scheduleHighlight()
            FrontendUI->>FrontendUI: markdownToHtml(æ–‡æœ¬)
            FrontendUI->>FrontendUI: _highlightCode()
            FrontendUI->>FrontendUI: hljs.highlightElement()
        else type == 'done'
            AJAX->>Frontend: 1ï¸âƒ£6ï¸âƒ£ æµç»“æŸ
        else type == 'error'
            AJAX->>FrontendUI: 1ï¸âƒ£7ï¸âƒ£ æ˜¾ç¤ºé”™è¯¯æç¤º
            FrontendUI->>FrontendUI: showNotification(error)
        end
    end
    
    FrontendUI->>FrontendUI: 1ï¸âƒ£8ï¸âƒ£ æ¶ˆæ¯æ˜¾ç¤ºå®Œæˆ
    FrontendUI->>User: ğŸ’¬ åœ¨èŠå¤©çª—å£æ˜¾ç¤ºå›ç­”

```

---

## ğŸ“ æµç¨‹è¯´æ˜

### æ ¸å¿ƒæ­¥éª¤

| æ­¥éª¤ | å‘ç”Ÿä½ç½® | å…·ä½“æ“ä½œ |
|------|---------|---------|
| 1ï¸âƒ£-2ï¸âƒ£ | å‰ç«¯ | ç”¨æˆ·é€‰æ‹©æ¨¡å¼ + è¾“å…¥é—®é¢˜ |
| 3ï¸âƒ£-4ï¸âƒ£ | å‰ç«¯ UI | æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ + åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨ |
| 5ï¸âƒ£-6ï¸âƒ£ | HTTP è¯·æ±‚ | å‘é€æµå¼è¯·æ±‚åˆ°åç«¯ |
| 7ï¸âƒ£-9ï¸âƒ£ | åç«¯é€»è¾‘ | æ ¹æ®æ¨¡å¼è°ƒç”¨å¯¹åº”å‡½æ•°ï¼ˆçŸ¥è¯†åº“/LLMï¼‰ |
| ğŸ”Ÿ-1ï¸âƒ£2ï¸âƒ£ | åç«¯å“åº” | æµå¼å‘é€ start â†’ stream â†’ done |
| 1ï¸âƒ£3ï¸âƒ£-1ï¸âƒ£8ï¸âƒ£ | å‰ç«¯å¤„ç† | æ¥æ”¶æµæ•°æ® â†’ è½¬æ¢ Markdown â†’ é«˜äº®ä»£ç  |

### çŸ¥è¯†åº“æ¨¡å¼çš„å…³é”®å‡½æ•°

```
å‰ç«¯:  app.js handleStreamQuery()
       â””â”€ api.js queryStream()
          â””â”€ POST /api/stream-query

åç«¯:  app.py stream_query()
       â””â”€ if mode == 'kb':
          â””â”€ kb.search()  â† ğŸ”‘ è°ƒç”¨çŸ¥è¯†åº“æœç´¢
             â””â”€ è¿”å›æœç´¢ç»“æœ
```

---

## ğŸ¯ å¯¹æ¯”ï¼šä¸‰ç§æ¨¡å¼

å¦‚æœä½ æ”¹æˆ **auto** æˆ– **llm** æ¨¡å¼ï¼Œåªæœ‰è¿™ä¸€å—ä¸åŒï¼š

```mermaid
graph TD
    A["Backend: stream_query()"]
    A -->|mode='kb'| B["kb.search<br/>è¿”å›çŸ¥è¯†åº“ç»“æœ"]
    A -->|mode='llm'| C["llm.chat<br/>è°ƒç”¨ OpenAI"]
    A -->|mode='auto'| D{æœ‰ç›¸å…³æ–‡æ¡£?}
    D -->|æœ‰| B
    D -->|æ— | C
    
    B --> E["æ ¼å¼åŒ–ç»“æœ"]
    C --> E
    E --> F["æµå¼å‘é€ç»™å‰ç«¯"]
```